{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pitch(y, sr, fmin=50, fmax=300):\n",
    "    \"\"\"\n",
    "    Extract the fundamental frequency (F0) using librosa's autocorrelation method.\n",
    "\n",
    "    Parameters:\n",
    "    - y: np.ndarray, audio time series.\n",
    "    - sr: int, sampling rate.\n",
    "    - fmin: float, minimum frequency to consider.\n",
    "    - fmax: float, maximum frequency to consider.\n",
    "\n",
    "    Returns:\n",
    "    - pitches: np.ndarray, pitch (F0) values over time.\n",
    "    - magnitudes: np.ndarray, magnitudes of the detected pitches.\n",
    "    \"\"\"\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    # Extract the pitch for each frame\n",
    "    pitch_values = []\n",
    "    for t in range(pitches.shape[1]):\n",
    "        index = magnitudes[:, t].argmax()\n",
    "        pitch = pitches[index, t]\n",
    "        pitch_values.append(pitch if pitch > 0 else np.nan)  # Use NaN for no pitch detected\n",
    "    \n",
    "    return np.array(pitch_values)\n",
    "\n",
    "# Usage\n",
    "file_path = r'C:\\Users\\syrym\\Downloads\\research_2\\audio.wav'\n",
    "y, sr = librosa.load(file_path, sr=None)\n",
    "pitches = extract_pitch(y, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pitch: 165.22 Hz\n",
      "Predicted Gender: Female\n"
     ]
    }
   ],
   "source": [
    "def classify_gender(pitches):\n",
    "    \"\"\"\n",
    "    Classify the gender based on the average pitch.\n",
    "\n",
    "    Parameters:\n",
    "    - pitches: np.ndarray, pitch (F0) values over time.\n",
    "\n",
    "    Returns:\n",
    "    - str, predicted gender ('Male' or 'Female').\n",
    "    \"\"\"\n",
    "    avg_pitch = np.nanmean(pitches)\n",
    "    print(f\"Average Pitch: {avg_pitch:.2f} Hz\")\n",
    "    \n",
    "    if avg_pitch > 165:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return 'Male'\n",
    "\n",
    "# Usage\n",
    "predicted_gender = classify_gender(pitches)\n",
    "print(f\"Predicted Gender: {predicted_gender}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lpc() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formants\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m formants \u001b[38;5;241m=\u001b[39m \u001b[43mextract_formants\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36mextract_formants\u001b[1;34m(y, sr, frame_length, hop_length)\u001b[0m\n\u001b[0;32m     21\u001b[0m frame \u001b[38;5;241m=\u001b[39m y[i:i \u001b[38;5;241m+\u001b[39m n_samples_per_frame]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Apply LPC\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlpc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m roots \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mroots(a)\n\u001b[0;32m     26\u001b[0m roots \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m roots \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mimag(r) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Keep only positive frequencies\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: lpc() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from scipy.signal import lfilter\n",
    "\n",
    "def extract_formants(y, sr, frame_length=0.025, hop_length=0.01):\n",
    "    \"\"\"\n",
    "    Extract the first two formant frequencies (F1, F2) using LPC.\n",
    "\n",
    "    Parameters:\n",
    "    - y: np.ndarray, audio time series.\n",
    "    - sr: int, sampling rate.\n",
    "    - frame_length: float, length of the frame (in seconds).\n",
    "    - hop_length: float, hop length between frames (in seconds).\n",
    "\n",
    "    Returns:\n",
    "    - formants: list of tuples, containing F1 and F2 for each frame.\n",
    "    \"\"\"\n",
    "    n_samples_per_frame = int(frame_length * sr)\n",
    "    hop_length_samples = int(hop_length * sr)\n",
    "    formants = []\n",
    "\n",
    "    for i in range(0, len(y) - n_samples_per_frame, hop_length_samples):\n",
    "        frame = y[i:i + n_samples_per_frame]\n",
    "        \n",
    "        # Apply LPC\n",
    "        a = librosa.lpc(frame, 2 + sr // 1000)\n",
    "        roots = np.roots(a)\n",
    "        roots = [r for r in roots if np.imag(r) >= 0]  # Keep only positive frequencies\n",
    "        formant_frequencies = np.angle(roots) * (sr / (2 * np.pi))\n",
    "\n",
    "        if len(formant_frequencies) >= 2:\n",
    "            formants.append((formant_frequencies[0], formant_frequencies[1]))\n",
    "    \n",
    "    return formants\n",
    "\n",
    "# Usage\n",
    "formants = extract_formants(y, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def extract_mfccs(y, sr, n_mfcc=13):\n",
    "    \"\"\"\n",
    "    Extract MFCCs from the audio signal.\n",
    "\n",
    "    Parameters:\n",
    "    - y: np.ndarray, audio time series.\n",
    "    - sr: int, sampling rate.\n",
    "    - n_mfcc: int, number of MFCC coefficients to extract.\n",
    "\n",
    "    Returns:\n",
    "    - mfccs: np.ndarray, MFCCs of the audio.\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfccs\n",
    "\n",
    "# Split dataset into features (X) and labels (y)\n",
    "def train_gender_classifier(X, y):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model for gender classification.\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray, feature matrix (MFCCs or other features).\n",
    "    - y: np.ndarray, labels (gender: 0 for male, 1 for female).\n",
    "\n",
    "    Returns:\n",
    "    - model: trained logistic regression model.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return model\n",
    "\n",
    "# Example for MFCCs and training\n",
    "mfccs = extract_mfccs(y, sr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_venv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
